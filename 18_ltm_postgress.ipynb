{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2316238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (1.0.7)\n",
      "Requirement already satisfied: langgraph-checkpoint-postgres in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: psycopg[binary,pool] in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (4.14.1)\n",
      "Requirement already satisfied: tzdata in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (2025.2)\n",
      "Requirement already satisfied: psycopg-binary==3.3.2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (3.3.2)\n",
      "Requirement already satisfied: psycopg-pool in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (3.3.0)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.13)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151f527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dddd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) System prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 3 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# 3) Memory extraction LLM\n",
    "# ----------------------------\n",
    "memory_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e08ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")\n",
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)\n",
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58385ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151f4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) Nodes\n",
    "# ----------------------------\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # existing memory (all items under namespace)\n",
    "    items = store.search(ns)\n",
    "    existing = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"(empty)\"\n",
    "\n",
    "    # latest user message\n",
    "    last_text = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=existing)),\n",
    "            {\"role\": \"user\", \"content\": last_text},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "\n",
    "    return {}\n",
    "chat_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    user_details = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT_TEMPLATE.format(user_details_content=user_details or \"(empty)\")\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a7f721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1982378ddd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4) Build graph\n",
    "# ----------------------------\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844c0bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Pranay! Always happy to help you with your ML journey.\n",
      "\n",
      "Let's break down Generative AI (GenAI) simply, in a way that might resonate with what you see in those YouTube ML tutorials:\n",
      "\n",
      "Imagine you have a super-smart artist or writer. Most AI you might have heard of before is like a critic – it can tell you if a picture is a cat or a dog, or if a sentence is grammatically correct. This is called \"discriminative AI\" because it *discriminates* or *classifies* existing things.\n",
      "\n",
      "**Generative AI (GenAI)**, on the other hand, is that actual *artist* or *writer*. Instead of just identifying things, it's designed to **create brand new, original content** that looks or sounds incredibly real and often very creative.\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "*   **It learns patterns:** GenAI models are trained on massive amounts of existing data – like millions of images, billions of text snippets, or thousands of hours of music. They learn the underlying patterns, styles, and rules of that data.\n",
      "*   **It generates new stuff:** Once it understands these patterns, it can then generate completely new things that follow those same patterns.\n",
      "    *   **Text:** Like writing an email, a poem, a story, or even computer code (e.g., ChatGPT).\n",
      "    *   **Images:** Creating realistic photos of people who don't exist, converting sketches into paintings, or generating art from a text description (e.g., Midjourney, DALL-E).\n",
      "    *   **Audio:** Composing music, generating speech, or creating sound effects.\n",
      "    *   **Video:** Making short video clips or animating images.\n",
      "\n",
      "So, in short, **GenAI is AI that can *create* new things** – be it text, images, audio, or video – based on the vast amount of information it has learned from. It's essentially teaching a computer to be creative!\n",
      "\n",
      "How does that sound, Pranay? Hope that makes it clearer!\n",
      "\n",
      "---\n",
      "\n",
      "Here are 3 further questions you might have, Pranay:\n",
      "\n",
      "1.  What are some common types of Generative AI models that I might see explained on YouTube (like GANs or Transformers)?\n",
      "2.  How do these GenAI models actually \"learn\" to create new things from data?\n",
      "3.  What are some practical applications of Generative AI that I might encounter in real life or in future projects?\n",
      "\n",
      "--- Stored Memories (from Postgres) ---\n",
      "The user learns ML from YouTube.\n",
      "The user's name is Pranay.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5) Use PostgresStore (PERSISTENT LTM)\n",
    "# ----------------------------\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    # IMPORTANT: run ONCE the first time you use this database\n",
    "    store.setup()\n",
    "\n",
    "    graph = builder.compile(store=store)\n",
    "\n",
    "    config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Pranay\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I learn ML from youtube\"}]}, config)\n",
    "\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Explain GenAI simply\"}]}, config)\n",
    "    print(out[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n--- Stored Memories (from Postgres) ---\")\n",
    "    for it in store.search((\"user\", \"u1\", \"details\")):\n",
    "        print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9b848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user learns ML from YouTube.\n",
      "The user's name is Pranay.\n"
     ]
    }
   ],
   "source": [
    "# Check persistance\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    ns = (\"user\", \"u1\", \"details\")\n",
    "    items = store.search(ns)\n",
    "\n",
    "for it in items:\n",
    "    print(it.value[\"data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
