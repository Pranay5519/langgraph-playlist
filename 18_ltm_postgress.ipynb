{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2316238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (0.6.4)\n",
      "Collecting langgraph\n",
      "  Using cached langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langgraph-checkpoint-postgres\n",
      "  Downloading langgraph_checkpoint_postgres-3.0.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting psycopg[binary,pool]\n",
      "  Downloading psycopg-3.3.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (4.14.1)\n",
      "Requirement already satisfied: tzdata in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from psycopg[binary,pool]) (2025.2)\n",
      "Collecting psycopg-binary==3.3.2 (from psycopg[binary,pool])\n",
      "  Downloading psycopg_binary-3.3.2-cp311-cp311-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting psycopg-pool (from psycopg[binary,pool])\n",
      "  Downloading psycopg_pool-3.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (1.2.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (2.1.1)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph)\n",
      "  Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n",
      "  Using cached langgraph_sdk-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph-checkpoint-postgres) (3.11.1)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.4.13)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langchain-core>=0.1->langgraph) (0.14.0)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph)\n",
      "  Using cached ormsgpack-1.12.2-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\prana\\desktop\\vs_code\\langraph\\myvenv\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.3.1)\n",
      "Downloading psycopg_binary-3.3.2-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.5 MB 2.0 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/3.5 MB 1.8 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/3.5 MB 1.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.5/3.5 MB 2.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.6/3.5 MB 2.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.9/3.5 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.3/3.5 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.5/3.5 MB 4.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.9/3.5 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.3/3.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.6/3.5 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.9/3.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.3/3.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 5.7 MB/s eta 0:00:00\n",
      "Using cached langgraph-1.0.7-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint_postgres-3.0.3-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.7/42.7 kB ? eta 0:00:00\n",
      "Using cached langgraph_checkpoint-4.0.0-py3-none-any.whl (46 kB)\n",
      "Using cached langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
      "Using cached langgraph_sdk-0.3.3-py3-none-any.whl (67 kB)\n",
      "Downloading psycopg-3.3.2-py3-none-any.whl (212 kB)\n",
      "   ---------------------------------------- 0.0/212.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 212.8/212.8 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading psycopg_pool-3.3.0-py3-none-any.whl (39 kB)\n",
      "Using cached ormsgpack-1.12.2-cp311-cp311-win_amd64.whl (117 kB)\n",
      "Installing collected packages: psycopg-pool, psycopg-binary, psycopg, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph-checkpoint-postgres, langgraph\n",
      "  Attempting uninstall: ormsgpack\n",
      "    Found existing installation: ormsgpack 1.10.0\n",
      "    Uninstalling ormsgpack-1.10.0:\n",
      "      Successfully uninstalled ormsgpack-1.10.0\n",
      "  Attempting uninstall: langgraph-sdk\n",
      "    Found existing installation: langgraph-sdk 0.2.0\n",
      "    Uninstalling langgraph-sdk-0.2.0:\n",
      "      Successfully uninstalled langgraph-sdk-0.2.0\n",
      "  Attempting uninstall: langgraph-checkpoint\n",
      "    Found existing installation: langgraph-checkpoint 2.1.1\n",
      "    Uninstalling langgraph-checkpoint-2.1.1:\n",
      "      Successfully uninstalled langgraph-checkpoint-2.1.1\n",
      "  Attempting uninstall: langgraph-prebuilt\n",
      "    Found existing installation: langgraph-prebuilt 0.6.4\n",
      "    Uninstalling langgraph-prebuilt-0.6.4:\n",
      "      Successfully uninstalled langgraph-prebuilt-0.6.4\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.6.4\n",
      "    Uninstalling langgraph-0.6.4:\n",
      "      Successfully uninstalled langgraph-0.6.4\n",
      "Successfully installed langgraph-1.0.7 langgraph-checkpoint-4.0.0 langgraph-checkpoint-postgres-3.0.3 langgraph-prebuilt-1.0.7 langgraph-sdk-0.3.3 ormsgpack-1.12.2 psycopg-3.3.2 psycopg-binary-3.3.2 psycopg-pool-3.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\prana\\Desktop\\VS_CODE\\Langraph\\myvenv\\Lib\\site-packages\\~rmsgpack'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langgraph-checkpoint-sqlite 2.0.11 requires langgraph-checkpoint<3.0.0,>=2.0.21, but you have langgraph-checkpoint 4.0.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151f527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import uuid\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dddd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 2) System prompt\n",
    "# ----------------------------\n",
    "SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant with memory capabilities.\n",
    "If user-specific memory is available, use it to personalize \n",
    "your responses based on what you know about the user.\n",
    "\n",
    "Your goal is to provide relevant, friendly, and tailored \n",
    "assistance that reflects the user’s preferences, context, and past interactions.\n",
    "\n",
    "If the user’s name or relevant personal context is available, always personalize your responses by:\n",
    "    – Always Address the user by name (e.g., \"Sure, Nitish...\") when appropriate\n",
    "    – Referencing known projects, tools, or preferences (e.g., \"your MCP server python based project\")\n",
    "    – Adjusting the tone to feel friendly, natural, and directly aimed at the user\n",
    "\n",
    "Avoid generic phrasing when personalization is possible.\n",
    "\n",
    "Use personalization especially in:\n",
    "    – Greetings and transitions\n",
    "    – Help or guidance tailored to tools and frameworks the user uses\n",
    "    – Follow-up messages that continue from past context\n",
    "\n",
    "Always ensure that personalization is based only on known user details and not assumed.\n",
    "\n",
    "In the end suggest 3 relevant further questions based on the current response and user profile\n",
    "\n",
    "The user’s memory (which may be empty) is provided as: {user_details_content}\n",
    "\"\"\"\n",
    "# ----------------------------\n",
    "# 3) Memory extraction LLM\n",
    "# ----------------------------\n",
    "memory_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e08ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryItem(BaseModel):\n",
    "    text: str = Field(description=\"Atomic user memory\")\n",
    "    is_new: bool = Field(description=\"True if new, false if duplicate\")\n",
    "class MemoryDecision(BaseModel):\n",
    "    should_write: bool\n",
    "    memories: List[MemoryItem] = Field(default_factory=list)\n",
    "memory_extractor = memory_llm.with_structured_output(MemoryDecision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58385ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_PROMPT = \"\"\"You are responsible for updating and maintaining accurate user memory.\n",
    "\n",
    "CURRENT USER DETAILS (existing memories):\n",
    "{user_details_content}\n",
    "\n",
    "TASK:\n",
    "- Review the user's latest message.\n",
    "- Extract user-specific info worth storing long-term (identity, stable preferences, ongoing projects/goals).\n",
    "- For each extracted item, set is_new=true ONLY if it adds NEW information compared to CURRENT USER DETAILS.\n",
    "- If it is basically the same meaning as something already present, set is_new=false.\n",
    "- Keep each memory as a short atomic sentence.\n",
    "- No speculation; only facts stated by the user.\n",
    "- If there is nothing memory-worthy, return should_write=false and an empty list.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151f4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 3) Nodes\n",
    "# ----------------------------\n",
    "def remember_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    # existing memory (all items under namespace)\n",
    "    items = store.search(ns)\n",
    "    existing = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"(empty)\"\n",
    "\n",
    "    # latest user message\n",
    "    last_text = state[\"messages\"][-1].content\n",
    "\n",
    "    decision: MemoryDecision = memory_extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=MEMORY_PROMPT.format(user_details_content=existing)),\n",
    "            {\"role\": \"user\", \"content\": last_text},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if decision.should_write:\n",
    "        for mem in decision.memories:\n",
    "            if mem.is_new and mem.text.strip():\n",
    "                store.put(ns, str(uuid.uuid4()), {\"data\": mem.text.strip()})\n",
    "\n",
    "    return {}\n",
    "chat_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "def chat_node(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    ns = (\"user\", user_id, \"details\")\n",
    "\n",
    "    items = store.search(ns)\n",
    "    user_details = \"\\n\".join(it.value.get(\"data\", \"\") for it in items) if items else \"\"\n",
    "\n",
    "    system_msg = SystemMessage(\n",
    "        content=SYSTEM_PROMPT_TEMPLATE.format(user_details_content=user_details or \"(empty)\")\n",
    "    )\n",
    "\n",
    "    response = chat_llm.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a7f721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x21d64b082d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 4) Build graph\n",
    "# ----------------------------\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"remember\", remember_node)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.add_edge(START, \"remember\")\n",
    "builder.add_edge(\"remember\", \"chat\")\n",
    "builder.add_edge(\"chat\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5) Use PostgresStore (PERSISTENT LTM)\n",
    "# ----------------------------\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    # IMPORTANT: run ONCE the first time you use this database\n",
    "    store.setup()\n",
    "\n",
    "    graph = builder.compile(store=store)\n",
    "\n",
    "    config = {\"configurable\": {\"user_id\": \"u1\"}}\n",
    "\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Hi, my name is Pranay\"}]}, config)\n",
    "    graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"I learn ML from youtube\"}]}, config)\n",
    "\n",
    "    out = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Explain GenAI simply\"}]}, config)\n",
    "    print(out[\"messages\"][-1].content)\n",
    "\n",
    "    print(\"\\n--- Stored Memories (from Postgres) ---\")\n",
    "    for it in store.search((\"user\", \"u1\", \"details\")):\n",
    "        print(it.value[\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check persistance\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\n",
    "\n",
    "with PostgresStore.from_conn_string(DB_URI) as store:\n",
    "    ns = (\"user\", \"u1\", \"details\")\n",
    "    items = store.search(ns)\n",
    "\n",
    "for it in items:\n",
    "    print(it.value[\"data\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
